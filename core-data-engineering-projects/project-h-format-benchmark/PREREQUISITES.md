# Prerequisites: Data Format Benchmark Project

## Required Bootcamps

### 30 Days of Python for Data and AI
**Mandatory Lessons:**
- Day 1-5: Python Fundamentals
- Day 6-10: Data Structures & Control Flow
- Day 11-15: Functions & Modules
- Day 21-25: Data Science Libraries (NumPy, Pandas)

**Nice to Have:**
- Day 16-20: Object-Oriented Programming

### 100 Days of Data and AI
**Mandatory Lessons:**
- Day 1-5: Data Processing Fundamentals
- Day 16-20: File Formats & Serialization
- Day 21-25: Columnar Storage (Parquet, ORC)
- Day 26-30: Data Compression Techniques
- Day 56-60: Performance Benchmarking
- Day 61-65: Storage Optimization

**Nice to Have:**
- Day 6-10: Data Structures & Algorithms
- Day 11-15: Memory Management
- Day 31-35: Data Lake Architecture

### 30 Days of SQL for Data and AI
**Mandatory Lessons:**
- Day 1-5: SQL Fundamentals
- Day 20-22: Performance Optimization

**Nice to Have:**
- Day 6-10: Advanced Queries
- Day 11-14: Data Manipulation

## Estimated Prerequisites Time
- **Mandatory**: 35-40 hours
- **Nice to Have**: 15-20 hours
- **Total Recommended**: 50-60 hours

## Skills Validation
Before starting this project, ensure you can:
- Work with multiple data formats (CSV, JSON, Parquet, Avro, ORC)
- Implement performance benchmarking and measurement
- Analyze storage efficiency and compression ratios
- Compare read/write performance across formats
- Understand trade-offs between different data formats
- Generate comprehensive benchmark reports
