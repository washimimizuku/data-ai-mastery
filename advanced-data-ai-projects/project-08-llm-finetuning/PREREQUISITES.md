# Prerequisites: LLM Fine-Tuning Platform Project

## Required Bootcamps

### 100 Days of Data and AI
**Mandatory Lessons:**
- Day 1-15: Python & Data Processing Fundamentals
- Day 51-55: Machine Learning Fundamentals
- Day 56-60: Model Evaluation & Validation
- Day 61-65: Deep Learning Fundamentals
- Day 66-70: Neural Networks & PyTorch
- Day 71-75: Natural Language Processing
- Day 81-85: Large Language Models (LLMs)
- Day 91-95: Model Fine-Tuning & Transfer Learning
- Day 96-100: Advanced LLM Topics

**Nice to Have:**
- Day 76-80: Text Embeddings & Vector Databases
- Day 86-90: LLM Integration & APIs

### 60 Days of Advanced Data and AI
**Mandatory Lessons:**
- Day 26-30: Advanced Model Deployment
- Day 31-35: Advanced MLOps Patterns
- Day 36-40: Model Versioning & Registry
- Day 41-45: Automated ML Pipelines
- Day 46-50: Model Monitoring & Observability
- Day 51-55: Distributed Training & GPU Optimization

**Nice to Have:**
- Day 16-20: Distributed Systems Design
- Day 21-25: Microservices Architecture
- Day 56-60: ML Platform Architecture

### 30 Days of Python for Data and AI
**Mandatory Lessons:**
- Day 1-20: Python Fundamentals & OOP
- Day 21-30: Data Science & ML Libraries

## Estimated Prerequisites Time
- **Mandatory**: 90-100 hours
- **Nice to Have**: 20-25 hours
- **Total Recommended**: 110-125 hours

## Skills Validation
Before starting this project, ensure you can:
- Implement advanced fine-tuning techniques (LoRA, QLoRA, full fine-tuning)
- Build distributed training pipelines for large models
- Handle dataset preparation and preprocessing for LLMs
- Deploy and serve fine-tuned models at scale
- Monitor training metrics and model performance
- Implement model evaluation and comparison frameworks
